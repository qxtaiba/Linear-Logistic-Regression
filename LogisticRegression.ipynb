{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n",
    "\n",
    "In the assignment, you will use gradient ascent to find the weights for the logistic regression.   \n",
    "\n",
    "As an example, we will use the widely-used breast cancer data set.  This data set is described here:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Getting, preprocessing, and understanding the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries\n",
    "# Import breastcancer dataset\n",
    "# Import preprocessing from sklearn\n",
    "# Import train_test_split from sklearn\n",
    "# Import numpy,math\n",
    "\n",
    "import sklearn\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset to a python variable cancer\n",
    "# Store target to a variable called y\n",
    "# Store feature to a variable called X\n",
    "\n",
    "breastData = load_breast_cancer()\n",
    "\n",
    "x = breastData.data\n",
    "y = breastData.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of data (X) and target (Y) values \n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "#### Splitting the data into train and test before scaling the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split() function to split the dataset\n",
    "# Store the return value of pervious step to X_train, X_test, y_train, y_test\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the data since we will be using gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the scaler of the dataset by using preprocessing.StandardScaler().fit()\n",
    "# Using this scale to scale the X_train and X_test using .transform()\n",
    "\n",
    "scaleVal = preprocessing.StandardScaler().fit(x)\n",
    "xTrain = scaleVal.transform(xTrain)\n",
    "xTest = scaleVal.transform(xTest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(426,)\n"
     ]
    }
   ],
   "source": [
    "# TODO - Print the shape of x_train and y_train \n",
    "\n",
    "print(xTrain.shape) # It should print (426, 30)\n",
    "print(yTrain.shape) # It should print (426,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a column of ones to the  matrices $X_{train}$ and  $X_{test}$\n",
    "After adding a column of ones $X_{train}=\\left[\\begin{matrix}\n",
    "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
    "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
    "\\vdots & \\vdots &\\vdots & & \\vdots \\\\\n",
    "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
    "\\end{matrix}\\right]$\n",
    "\n",
    "Similarly for $X_{test}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trainng data has dimensions:  (426, 31) . The testing data has dimensions:  (143, 31)\n",
      "[[ 1.         -1.12392703 -1.02615481 ... -1.35236887  1.06165929\n",
      "  -0.20757752]\n",
      " [ 1.         -1.24662117 -1.70333134 ... -1.74506282  0.33042245\n",
      "  -0.1349828 ]\n",
      " [ 1.         -0.13839777 -0.85860597 ... -0.34086601 -0.5998014\n",
      "  -1.04435637]\n",
      " ...\n",
      " [ 1.          1.54012613  2.20614143 ...  1.21041973 -0.13388059\n",
      "   0.91736357]\n",
      " [ 1.         -0.18384004  0.35612307 ...  1.69310287 -0.15167617\n",
      "   1.28310797]\n",
      " [ 1.          0.16549742  0.53530723 ...  1.04749514  1.28976635\n",
      "   1.41056435]]\n",
      "[[ 1.         -0.33436757 -0.76086916 -0.36366965 -0.4015563   0.29460492\n",
      "  -0.4721     -0.34211437 -0.39256238 -0.297985    0.2696836  -0.70658247\n",
      "  -0.82235759 -0.80940437 -0.49871449  0.56136312 -0.30449397 -0.2832842\n",
      "  -0.07723404  0.69107992  0.35218836 -0.52375102 -0.93589962 -0.54958484\n",
      "  -0.51890617  0.69836738 -0.301944   -0.23070563 -0.13713413  0.77531212\n",
      "   0.65912586]\n",
      " [ 1.         -0.91659667 -1.4729517  -0.95886805 -0.81935497 -1.50943904\n",
      "  -1.27280001 -1.07607798 -1.09188883 -1.34945669 -0.76091455 -0.44527566\n",
      "  -0.82634915 -0.52377171 -0.47957301 -0.29967179 -1.08113501 -0.99665755\n",
      "  -1.33338569 -0.50517569 -0.42738765 -0.80952492 -1.21761938 -0.86948474\n",
      "  -0.7217693  -0.66931243 -1.08986665 -1.21688457 -1.14315542 -0.26330303\n",
      "  -0.39322051]]\n"
     ]
    }
   ],
   "source": [
    "# Append a column of ones to x_train \n",
    "# Create a column vector of ones by using np.ones and reshape\n",
    "# Append a column of ones in the beginning of x_train by using np.hstack\n",
    "\n",
    "rowOnes = np.ones(len(xTrain))\n",
    "colOnes = rowOnes.reshape(-1,1)\n",
    "\n",
    "xTrain = np.hstack((colOnes, xTrain))\n",
    "\n",
    "# Now do the same for the test data\n",
    "\n",
    "rowOnes = np.ones(len(xTest))\n",
    "colOnes = rowOnes.reshape(-1,1)\n",
    "\n",
    "xTest = np.hstack((colOnes, xTest))\n",
    "\n",
    "\n",
    "# We can check that everything worked correctly by printing out the new dimensions:\n",
    "\n",
    "print(\"The trainng data has dimensions: \", xTrain.shape, \". The testing data has dimensions: \",xTest.shape)\n",
    "\n",
    "# Looking at the first two rows of X_train to check everything worked as expected\n",
    "\n",
    "print(xTrain)\n",
    "print(xTest[0:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# Printing the names of all the features\n",
    "\n",
    "print(breastData.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add your own code here to better understand the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Before writing the gradient ascent code, first write some helpful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " \n",
    "### Sigmoid($z$)\n",
    "The first function you will write is sigmoid($z$)\n",
    "\n",
    "sigmoid($z$) takes as input a column vector of real numbers, $z^T = [z_1, z_2, ..., z_{N'}]$, where $N'$ is the number of  examples\n",
    "\n",
    "It should produce as output a column vector $\\left[\\frac{1}{1+e^{-z_1}},\\frac{1}{1+e^{-z_2}},...,\\frac{1}{1+e^{-z_{N'}}}\\right]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the sigmoid function\n",
    "\n",
    "def sigmoid(z):\n",
    "    \n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing ${\\bf w}$\n",
    "For testing the next functions, we create a coefficient vector, ${\\bf w}$.\n",
    "We will initialize the coeffients to be $0$, i.e. ${\\bf w}^T = [0,0,\\ldots ,0]$ (We could have initialized ${\\bf w}$ to any values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize w using np.zeros()\n",
    "\n",
    "wCoefficients = np.zeros((xTrain.shape[1],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our hypothesis, $h({\\bf x})$\n",
    "The next  function to write is our hypothesis function. \n",
    "\n",
    "For example if our design matrix $X$ consists of single example $X=[1,x_1,x_2,\\ldots,x_d]$ and  weights ${\\bf w}^T=[w_0,w_2,\\ldots, w_d]$, it returns $h({\\bf x})=\\frac{1}{1+e^{-\\left({w_{0}\\cdot 1 +w_1\\cdot x_1+\\cdots w_d\\cdot x_d}\\right)}}$\n",
    "\n",
    "If given a  matrix consisting of $N'$ examples \n",
    "$X=\\left[\\begin{matrix}\n",
    "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
    "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
    "\\vdots & \\vdots &\\vdots & & \\vdots \\\\\n",
    "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
    "\\end{matrix}\\right]$\n",
    "and  weights ${\\bf w}^T=[w_0,w_2,\\ldots, w_d]$, the function returns a column vector\n",
    "$[h({\\bf x}^{(1)}),h({\\bf x}^{(2)},\\ldots, h({\\bf x}^{(N')}]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probability that a patient has cancer \n",
    "# Write the hypothesis function \n",
    "def hypothesis(xTrain, wCoefficients): #xTrain??\n",
    "\n",
    "    return sigmoid(np.dot(xTrain,wCoefficients)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Likelihood Function.\n",
    "Write the code to calculate the log likelihood function $\\ell({\\bf w})=\n",
    "\\sum_{i=1}^{N'}y^{(i)}\\ln(h({\\bf x}^{(i)})) +(1- y^{(i)})\\ln(1-h({\\bf x}^{(i)}))$\n",
    "\n",
    "The input is a matrix consisting of $N'$ examples $X=\\left[\\begin{matrix}\n",
    "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
    "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
    "\\vdots & \\vdots &\\vdots & & \\vdots \\\\\n",
    "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
    "\\end{matrix}\\right]$\n",
    "and a column vector ${\\bf y}^T=[y^{(1)},y^{(2)},\\dots,y^{(N')}]$ of labels for $X$.\n",
    "\n",
    "The output is $\\ell({\\bf w})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the log likelihood function \n",
    "def log_likelihood(xTrain , yTrain , wCoefficients ): #xTrain?? yTrain??\n",
    "    m = xTrain.shape[0]\n",
    "    hX = hypothesis(xTrain,wCoefficients)\n",
    "    logL = (1/m) * np.sum(yTrain * np.log(hX)+(1-yTrain)*np.log(1-hX))\n",
    "\n",
    "    return logL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Ascent\n",
    "Now write the code to perform gradient ascent.  You will use the update rule from the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Write the gradient ascent function \n",
    "def logisticRegressionGradientAscent(xTrain, yTrain, learnRate, numIterations):\n",
    "    # For every 100 iterations, store the log_likelihood for the current w\n",
    "    # Initializing log_likelihood to be an empty list  \n",
    "    # Initialize w to be a zero vector of shape x_train.shape[1],1\n",
    "    # Initialize N to the number of training examples\n",
    "    \n",
    "    yTrain = yTrain.reshape(yTrain.shape[0], 1)\n",
    "    logLikelihoodValues = []\n",
    "    wCoefficients = np.zeros((xTrain.shape[1],1))\n",
    "    N = xTrain.shape[0]\n",
    "    \n",
    "    for i in range(numIterations):\n",
    "        hX = hypothesis(xTrain,wCoefficients)\n",
    "        gradient = (1/N) * np.dot(xTrain.T, hX-yTrain)\n",
    "        wCoefficients =  wCoefficients - (learnRate*gradient)\n",
    "\n",
    "        if (i%100 == 0):\n",
    "            logLikelihoodValues.append(log_likelihood(xTrain , yTrain , wCoefficients) )\n",
    "\n",
    "\n",
    "    return wCoefficients, logLikelihoodValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After completing the code above, run the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wCoefficients [[-0.6941233 ]\n",
      " [ 0.16140642]\n",
      " [ 0.20834556]\n",
      " [ 0.28733743]\n",
      " [-0.16262661]\n",
      " [-0.34364002]\n",
      " [ 3.3879749 ]\n",
      " [-2.35039744]\n",
      " [-2.6810812 ]\n",
      " [ 1.21778171]\n",
      " [ 0.25294747]\n",
      " [-4.11587187]\n",
      " [ 0.38846146]\n",
      " [-1.59663056]\n",
      " [-2.61265856]\n",
      " [ 0.41368688]\n",
      " [ 1.28026885]\n",
      " [-0.96950496]\n",
      " [-1.21782745]\n",
      " [ 0.26931051]\n",
      " [ 1.15406252]\n",
      " [-1.42666293]\n",
      " [-3.10371887]\n",
      " [-1.06854143]\n",
      " [-1.57831195]\n",
      " [-1.42300936]\n",
      " [ 1.01679151]\n",
      " [-2.20054986]\n",
      " [-1.37958673]\n",
      " [-2.56130243]\n",
      " [-0.45013478]]\n",
      "Log Likelihood Values [-0.22384709162123043, -0.06125042707832265, -0.052883345046471165, -0.04893197156991956, -0.04640511169087769, -0.04454293141363669, -0.04305529344330106, -0.04180627980192731, -0.04072311178954044, -0.03976280846709119, -0.038897963955739225, -0.038109983729356776, -0.037385592339836266, -0.036714908025373305, -0.03609032133815499, -0.03550581005075451, -0.03495650218469742, -0.03443838607041652, -0.03394811085033023, -0.03348284459994891, -0.03304017040410936, -0.0326180082482667, -0.03221455500586959, -0.03182823746912412, -0.031457675019308386, -0.031101649578530018, -0.030759081165356562, -0.03042900783141431, -0.030110569067890013, -0.02980299199027363, -0.029505579767782685, -0.029217701880335276, -0.028938785873323044, -0.028668310347097617, -0.02840579896963985, -0.028150815341208963, -0.02790295857161128, -0.027661859456070005, -0.027427177155978526, -0.02719859630717538, -0.026975824491622412, -0.026758590019137763, -0.026546639974631914, -0.026339738493504725, -0.026137665233794884, -0.025940214018570707, -0.025747191626109715, -0.025558416708786853, -0.02537371882440495, -0.025192937566052977]\n"
     ]
    }
   ],
   "source": [
    "# Set the learning_rate\n",
    "learnRate = 0.5 \n",
    "# Set the num_iters\n",
    "numIterations = 5000\n",
    "# Run the Logistic_Regresion_Gradient_Ascent() and store the returned values\n",
    "wCoefficient, logLikelihoodValue = logisticRegressionGradientAscent(xTrain, yTrain, learnRate, numIterations)\n",
    "print(\"wCoefficients\",wCoefficient)\n",
    "print(\"Log Likelihood Values\",logLikelihoodValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Likelihood v/s Number of Iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to plot Likelihood v/s Number of Iterations.\n",
    "iters = np.array(range(0,numIterations,100))\n",
    "plt.plot(iters,logLikelihoodValue,'.-',color='green')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Likelihood')\n",
    "plt.title(\"Likelihood vs Number of Iterations.\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluating your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hypothesis(...) to predict.\n",
    "\n",
    "yPred = hypothesis(xTest,wCoefficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9578947368421052\n",
      "Recall:  0.9578947368421052\n",
      "F1:  0.9578947368421052\n",
      "Confusion Matrix: \n",
      "TP:  91  FN:  4  FP:  4  TN:  44\n"
     ]
    }
   ],
   "source": [
    "TP=0\n",
    "FP=0\n",
    "FN=0\n",
    "TN=0\n",
    "\n",
    "for i in range(yTest.shape[0]):\n",
    "    if yTest[i] == 0:\n",
    "        if yPred[i] < 0.5: TN+=1\n",
    "        else: FP+=1\n",
    "    else:\n",
    "        if yPred[i] >= 0.5: TP += 1\n",
    "        else: FN += 1\n",
    "\n",
    "recallVal = TP/(TP+FN)\n",
    "precisionVal = TP/(TP+FP)\n",
    "fOneVal = (2*precisionVal*recallVal)/(precisionVal + recallVal)\n",
    "\n",
    "print(\"Precision: \",precisionVal)\n",
    "print(\"Recall: \",recallVal)\n",
    "print(\"F1: \",fOneVal)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(\"TP: \",TP,\" FN: \",FN,\" FP: \",FP,\" TN: \",TN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
